from django.db import models
from django.core.files.storage import FileSystemStorage
from django.conf import settings


class KeyValue(models.Model):
    key_field = models.CharField(max_length=250, default='', primary_key=True)
    value = models.TextField(max_length=100000, default='')

    class Meta:
        indexes = [models.Index(fields=['key_field'])]


class Config(models.Model):
    chatgpt_api_key = models.CharField(
        max_length=100,
        verbose_name='OpenAI api key',
        default=""
    )
    chat_gpt_temperature = models.FloatField(
        verbose_name='temperature',
        default=0,
        help_text='''Controls the “creativity” or randomness of the text generated by GPT. A higher temperature (e.g., 0.7)
        results in more diverse and creative output, while a lower temperature (e.g., 0.2) 
        makes the output more deterministic and focused.
        <br><br>
        In practice, temperature affects the probability distribution over the possible tokens 
        at each step of the generation process. A temperature of 0 would make the model completely deterministic, 
        always choosing the most likely token.
        '''
    )
    chat_gpt_top_p = models.FloatField(
        verbose_name='top_p',
        default=1,
        help_text='''Top_p sampling is an alternative to temperature sampling. Instead of considering all possible tokens,
         GPT considers only a subset of tokens (the nucleus) whose cumulative probability mass adds up to a certain threshold (top_p).
         <br><br>
         For example, if top_p is set to 0.1, GPT will consider only the tokens that make up the top 10% of the probability 
         mass for the next token. This allows for dynamic vocabulary selection based on context.
         '''
    )
    chat_gpt_frequency_penalty = models.FloatField(
        verbose_name='frequency_penalty',
        default=0,
        help_text='''This parameter is used to discourage the model from repeating the same words or phrases too frequently
         within the generated text. It is a value that is added to the log-probability of a token each time it occurs 
         in the generated text. A higher frequency_penalty value will result in the model being more conservative in 
         its use of repeated tokens.'''
    )
    chat_gpt_presence_penalty = models.FloatField(
        verbose_name='presence_penalty',
        default=0,
        help_text='''
        This parameter is used to encourage the model to include a diverse range of tokens in the generated text. 
        It is a value that is subtracted from the log-probability of a token each time it is generated.
        A higher presence_penalty value will result in the model being more likely to generate tokens
        that have not yet been included in the generated text.
        '''
    )

    class Meta:
        verbose_name = 'Settings'
        verbose_name_plural = 'Settings'

    def __str__(self):
        return 'Settings'


class Step(models.Model):
    dalle_request = models.TextField(
        max_length=100000,
        verbose_name='DALL-E prompt to generate image'
    )
    dalle_response = models.ImageField(
        storage=FileSystemStorage(location=settings.FILES_FOLDER)
    )
    suggest_changes_request = models.TextField(
        max_length=20000,
        verbose_name="'Suggest changes' request",
    )
    suggest_changes_response = models.TextField(
        max_length=10000,
        verbose_name="'Suggest changes' response",
    )
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        verbose_name = 'Step'
        verbose_name_plural = 'Steps'
